{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Web Scrapping for Sephora</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Input the url of a product and get all info</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Function 1: get general information of a product </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general(product_page):\n",
    "    product_url = 'https://www.sephora.com' + product_page\n",
    "    response = requests.get(product_url)\n",
    "    results_page = BeautifulSoup(response.content,'lxml')\n",
    "    #category\n",
    "    string = results_page.find_all('script')[5].get_text()\n",
    "    pattern = r'\"displayName\":\"([a-zA-Z &]+)\"'\n",
    "    match = re.findall(pattern,string)\n",
    "    category = match[-1]\n",
    "    subcategory = match[-2]\n",
    "    #product general info\n",
    "    names = results_page.find('h1',{'data-comp':\"DisplayName Flex Box\"})\n",
    "    brand_name = names.find_all('span')[0].get_text()  \n",
    "    product_name = names.find_all('span')[1].get_text()  \n",
    "    loves = results_page.find('span',{'data-at':\"product_love_count\"}).get_text()\n",
    "    price = results_page.find('div',{'data-comp':\"Price Box\"}).get_text().split()[0] #get the original price rather than discounted one\n",
    "    pattern = r'P\\d+'\n",
    "    match = re.search(pattern,product_page)\n",
    "    product_id = match[0]\n",
    "    return [product_id, brand_name, product_name, category, subcategory, loves, price]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Function 2: get general stats for all of a product's reviews\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_stats(result_json):\n",
    "    try: \n",
    "        n = len(list(result_json['Includes']['Products'].values()))\n",
    "        review_stats = list(result_json['Includes']['Products'].values())[n-1]['ReviewStatistics']#get the conclusive review stats\n",
    "        total_review = review_stats['TotalReviewCount'] \n",
    "        avg_rating = review_stats['AverageOverallRating'] \n",
    "        recommended_count = review_stats['RecommendedCount'] \n",
    "        #get star counts\n",
    "        dic = dict()\n",
    "        for item in review_stats['RatingDistribution']:\n",
    "            values = list(item.values())\n",
    "            dic[values[0]] = values[1]\n",
    "        if 1 in dic:\n",
    "            onestar_count = dic[1]\n",
    "        else:\n",
    "            onestar_count = 0\n",
    "        if 2 in dic:\n",
    "            twostar_count = dic[2]\n",
    "        else:\n",
    "            twostar_count = 0\n",
    "        if 3 in dic:\n",
    "            threestar_count = dic[3]\n",
    "        else:\n",
    "            threestar_count = 0\n",
    "        if 4 in dic:\n",
    "            fourstar_count = dic[4]\n",
    "        else:\n",
    "            fourstar_count = 0\n",
    "        if 5 in dic:\n",
    "            fivestar_count = dic[5]\n",
    "        else:\n",
    "            fivestar_count = 0\n",
    "    except:\n",
    "        total_review, avg_rating, recommended_count, onestar_count, twostar_count, threestar_count, fourstar_count, fivestar_count = 0,0,0,0,0,0,0,0\n",
    "    return [total_review, avg_rating, recommended_count, onestar_count, twostar_count, \n",
    "            threestar_count, fourstar_count, fivestar_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Function 3: get detailed information of a single review\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(url):\n",
    "    output = {}\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "    result_json = json.loads(response.content.decode('utf-8'))\n",
    "    for i in range(len(result_json['Results'])):\n",
    "        review_content=result_json['Results'][i]\n",
    "        review_id = review_content['Id']\n",
    "        rating=review_content['Rating']\n",
    "        review_text=review_content['ReviewText']\n",
    "        helpfulness=review_content['Helpfulness']\n",
    "        try: #get membership level(if there is a nonetype, level = None)\n",
    "            level_string=review_content['AdditionalFields']['sociallockup']['Value']\n",
    "            level_pattern=r'biTier=[a-zA-Z]+'\n",
    "            level=re.search(level_pattern,level_string)[0]\n",
    "        except:\n",
    "            level=None\n",
    "        positive_count=review_content['TotalPositiveFeedbackCount']\n",
    "        negative_count=review_content['TotalNegativeFeedbackCount']\n",
    "        title= review_content['Title']\n",
    "        recommended=review_content['IsRecommended']\n",
    "        output[review_id] = [rating, title, review_text, level, helpfulness, positive_count, negative_count, recommended]\n",
    "    return output   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Function 4: go to bazaarvoice and get all the review details and stats\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bazaarvoice(product_id):\n",
    "    review_url = f\"https://api.bazaarvoice.com/data/reviews.json?Filter=contentlocale%3Aen*&Filter=ProductId%3A{product_id}&Sort=TotalPositiveFeedbackCount%3Adesc&Limit=100&Offset=0&Include=Products%2CComments&Stats=Reviews&passkey=rwbw526r2e7spptqd2qzbkp7&apiversion=5.4&Locale=en_US\"\n",
    "    response = requests.get(review_url)\n",
    "    result_json = json.loads(response.content.decode('utf-8'))\n",
    "    review_stats = get_review_stats(result_json)\n",
    "    total_review = review_stats[0] #get total number of reviews\n",
    "    all_reviews = dict()\n",
    "    for i in range(0,total_review,100):  #loop for all review pages\n",
    "        next_url = f\"https://api.bazaarvoice.com/data/reviews.json?Filter=contentlocale%3Aen*&Filter=ProductId%3A{product_id}&Sort=TotalPositiveFeedbackCount%3Adesc&Limit=100&Offset={i}&Include=Products%2CComments&Stats=Reviews&passkey=rwbw526r2e7spptqd2qzbkp7&apiversion=5.4&Locale=en_US\"\n",
    "        all_reviews.update(get_reviews(next_url))\n",
    "    return review_stats, all_reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Function 5: finalize to one function and get all the related info of a product\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_product_final(product_page): \n",
    "    output = list()\n",
    "    general = get_general(product_page)\n",
    "    product_id = general[0]\n",
    "    output.extend(general)\n",
    "    review_stats, all_reviews = bazaarvoice(product_id)\n",
    "    output.extend(review_stats)\n",
    "    output.append(all_reviews)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Web Scrapping for all allure products</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "STEP 1: get a dictionary of all the urls of allure products\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    try:\n",
    "        results_page = BeautifulSoup(response.content,'lxml')\n",
    "        script_list = results_page.find('script',{'data-comp':\"PageJSON\", 'id':\"linkJSON\", 'type':\"text/json\"}).text\n",
    "        json_list = json.loads(script_list)[3]\n",
    "        all_products = json_list['props']['items'][1]['skus']\n",
    "        url_dic = dict()\n",
    "        for product in all_products:\n",
    "            brand_name = product['sku']['brandName']\n",
    "            product_name = product['sku']['productName']\n",
    "            name = brand_name + '/' + product_name\n",
    "            url = product['sku']['targetUrl']\n",
    "            url_dic[name] = url\n",
    "        return url_dic\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "STEP 2: get all allure products info\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this!!!!!!!\n",
    "categories = ['makeup','skin-care','fragrance','hair','bath-body','tools-brushes']\n",
    "all_allure = list()\n",
    "for category in categories:\n",
    "    category_url = 'https://www.sephora.com/beauty/allure-best-of-beauty-' + category\n",
    "    l = list(get_url(category_url).values())\n",
    "    n = len(l)\n",
    "    i=0\n",
    "    for item in l:\n",
    "        print(category, i,'/',n)\n",
    "        one_product=one_product_final(item)\n",
    "        all_allure.append(one_product)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "STEP 3: transform the data into df and write into csv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_allure_df = pd.DataFrame(all_allure, columns = ['product_id', 'brand_name', 'product_name', 'category', 'subcategory', 'loves', 'price', 'total_review', 'avg_rating', 'recommended_count', 'onestar_count', 'twostar_count', 'threestar_count', 'fourstar_count', 'fivestar_count', 'all_reviews'])\n",
    "all_allure_df.drop_duplicates(keep=False,inplace=True) #remove duplicates\n",
    "all_allure_df = all_allure_df.reset_index(drop=True)\n",
    "all_allure_df.to_csv('all_allure.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Web Scrapping for all non-allure products</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "STEP 1: get the amounts of non-allure products needed to scrape for each category\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_allure_df\n",
    "c = df.groupby('category')\n",
    "allure_amounts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeup\n",
    "data1 = df[df['category'] == 'Makeup']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "data2.index = data2.index.str.replace(' &', '')\n",
    "data2.index = data2.index.str.replace(' ', '-')\n",
    "makeup = dict(data2)\n",
    "makeup['face'] += makeup.pop('makeup-palettes')\n",
    "makeup = {'/eye-makeup': 37, '/face-makeup': 33, '/lips-makeup': 25, '/makeup-applicators': 7, '/cheek-makeup': 4, '/nails-makeup': 1, '/makeup-accessories': 1}\n",
    "allure_amounts['Makeup'] = makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skincare\n",
    "data1 = df[df['category'] == 'Skincare']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "skincare = dict(data2)\n",
    "skincare = {'/moisturizing-cream-oils-mists': 18,\n",
    " '/face-mask': 14,\n",
    " '/facial-treatments': 12,\n",
    " '/eye-treatment-dark-circle-treatment': 8,\n",
    " '/cleanser': 6,\n",
    " '/self-tanning-products': 4,\n",
    " '/sunscreen-sun-protection': 2,\n",
    " '/skin-care-tools': 1}\n",
    "allure_amounts['Skincare'] = skincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hair\n",
    "data1 = df[df['category'] == 'Hair']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "hair = dict(data2)\n",
    "hair = {'/hair-products-treatments': 17, '/shampoo-conditioner': 13, '/hair-styling-tools': 5}\n",
    "allure_amounts['Hair'] = hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fragrance\n",
    "data1 = df[df['category'] == 'Fragrance']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "fragrance = dict(data2)\n",
    "fragrance = {'/fragrances-for-women': 16, '/fragrances-for-men': 3}\n",
    "allure_amounts['Fragrance'] = fragrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bath & body\n",
    "data1 = df[df['category'] == 'Bath & Body']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "bath_body = dict(data2)\n",
    "bath_body = {'/body-moisturizers': 6, '/body-care': 2, '/bronzer-self-tanner-bath-body': 1, '/bath-and-body-soap': 1}\n",
    "allure_amounts['Bath & Body'] = bath_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools & brushes\n",
    "data1 = df[df['category'] == 'Tools & Brushes']\n",
    "data2 = data1.groupby('subcategory').size().sort_values(ascending=False)\n",
    "data2.index = data2.index.str.lower()\n",
    "tools_brushes = dict(data2)\n",
    "tools_brushes = {'/small-tools': 2, '/professional-beauty-tools': 1}\n",
    "allure_amounts['Tools & Brushes'] = tools_brushes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get all non-allure products based on allure_amounts\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allure_id = list(df['product_id'])\n",
    "def get_url(url,n):\n",
    "    url_dic = dict()\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    try:\n",
    "        results_page = BeautifulSoup(response.content,'lxml')\n",
    "        number_of_product = int(results_page.find('span',{'data-at':\"number_of_products\"}).get_text().split()[0]) #get total number of products\n",
    "        num = 5*n\n",
    "        while len(url_dic.keys()) < num:\n",
    "            chosen_product = random.randint(1,number_of_product)#randomly select one product\n",
    "            if chosen_product % 300 != 0:\n",
    "                chosen_page = chosen_product // 300 + 1\n",
    "                chosen_product_loc = chosen_product % 300 - 1\n",
    "            else:\n",
    "                chosen_page = chosen_product / 300\n",
    "                chosen_product_loc = 299\n",
    "            current_page_url = url + '?pageSize=300&currentPage='+str(chosen_page)\n",
    "            current_response = requests.get(current_page_url)\n",
    "            current_result_page = BeautifulSoup(current_response.content,'lxml')\n",
    "            script_list = current_result_page.find('script',{'data-comp':\"PageJSON\", 'id':\"linkJSON\", 'type':\"text/json\"}).text\n",
    "            json_list = json.loads(script_list)[2]\n",
    "            chosen_product_info = json_list['props']['products'][chosen_product_loc]\n",
    "            productId = chosen_product_info['productId']\n",
    "            brand_name = chosen_product_info['brandName']\n",
    "            product_name = chosen_product_info['displayName']\n",
    "            name = brand_name + '/' + product_name\n",
    "            product_url = chosen_product_info['targetUrl']\n",
    "            if productId in allure_id or name in all_url: #ensure it is non-allure and unique\n",
    "                pass\n",
    "            else:\n",
    "                review_url = f\"https://api.bazaarvoice.com/data/reviews.json?Filter=contentlocale%3Aen*&Filter=ProductId%3A{productId}&Sort=TotalPositiveFeedbackCount%3Adesc&Limit=100&Offset=0&Include=Products%2CComments&Stats=Reviews&passkey=rwbw526r2e7spptqd2qzbkp7&apiversion=5.4&Locale=en_US\"\n",
    "                response = requests.get(review_url)\n",
    "                result_json = json.loads(response.content.decode('utf-8'))\n",
    "                try:\n",
    "                    x = len(list(result_json['Includes']['Products'].values())) #avoid 0 review products\n",
    "                except:\n",
    "                    x = 0\n",
    "                if x == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    url_dic[name] = product_url\n",
    "        return url_dic\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get all non-allure urls</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this !!!\n",
    "all_url = dict()\n",
    "for key1 in allure_amounts:\n",
    "    for key2 in allure_amounts[key1]:\n",
    "        sub_url = 'https://www.sephora.com/shop' + key2\n",
    "        amount = allure_amounts[key1][key2]\n",
    "        output = get_url(sub_url,amount)\n",
    "        all_url.update(output)\n",
    "        print(sub_url,5*amount,len(output.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get all non-allure products info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run this!!!!!\n",
    "l = list(all_url.values())\n",
    "n = len(l)\n",
    "i=0\n",
    "all_non_allure = list()\n",
    "for item in l:\n",
    "    print(i,'/',n)\n",
    "    one_product=one_product_final(item)\n",
    "    all_non_allure.append(one_product)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>write non-allures into df and csv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_allure_df = pd.DataFrame(all_allure, columns = ['product_id', 'brand_name', 'product_name', 'category', 'subcategory', 'loves', 'price', 'total_review', 'avg_rating', 'recommended_count', 'onestar_count', 'twostar_count', 'threestar_count', 'fourstar_count', 'fivestar_count', 'all_reviews'])\n",
    "non_allure_df.to_csv('non_allure.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Web Scrapping for all men products</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url,n):\n",
    "    url_dic = dict()\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    try:\n",
    "        results_page = BeautifulSoup(response.content,'lxml')\n",
    "        number_of_product = int(results_page.find('span',{'data-at':\"number_of_products\"}).get_text().split()[0])\n",
    "        for i in range(n): #get all men products\n",
    "            chosen_product = random.randint(1,number_of_product)\n",
    "            if chosen_product % 300 != 0:\n",
    "                chosen_page = chosen_product // 300 + 1\n",
    "                chosen_product_loc = chosen_product % 300 - 1\n",
    "            else:\n",
    "                chosen_page = chosen_product / 300\n",
    "                chosen_product_loc = 299\n",
    "            current_page_url = url + '?pageSize=300&currentPage='+str(chosen_page)\n",
    "            current_response = requests.get(current_page_url)\n",
    "            current_result_page = BeautifulSoup(current_response.content,'lxml')\n",
    "            script_list = current_result_page.find('script',{'data-comp':\"PageJSON\", 'id':\"linkJSON\", 'type':\"text/json\"}).text\n",
    "            json_list = json.loads(script_list)[2]\n",
    "            chosen_product_info = json_list['props']['products'][chosen_product_loc]\n",
    "            productId = chosen_product_info['productId']\n",
    "            brand_name = chosen_product_info['brandName']\n",
    "            product_name = chosen_product_info['displayName']\n",
    "            name = brand_name + '/' + product_name\n",
    "            product_url = chosen_product_info['targetUrl']\n",
    "            if name in all_url:\n",
    "                pass\n",
    "            else:\n",
    "                review_url = f\"https://api.bazaarvoice.com/data/reviews.json?Filter=contentlocale%3Aen*&Filter=ProductId%3A{productId}&Sort=TotalPositiveFeedbackCount%3Adesc&Limit=100&Offset=0&Include=Products%2CComments&Stats=Reviews&passkey=rwbw526r2e7spptqd2qzbkp7&apiversion=5.4&Locale=en_US\"\n",
    "                response = requests.get(review_url)\n",
    "                result_json = json.loads(response.content.decode('utf-8'))\n",
    "                try:\n",
    "                    x = len(list(result_json['Includes']['Products'].values()))\n",
    "                except:\n",
    "                    x = 0\n",
    "                if x == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    url_dic[name] = product_url\n",
    "        return url_dic\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get all men urls</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this!!!!\n",
    "all_url = dict()\n",
    "allure_amounts = {'/gift-sets-for-men':27,'/mens-perfume':246,'/mens-facial-products':106,'/mens-grooming':52,'/mens-hair-care':49,'/mens-personal-care':64}\n",
    "for key in allure_amounts:\n",
    "        sub_url = 'https://www.sephora.com/shop' + key\n",
    "        amount = allure_amounts[key]\n",
    "        output = get_url(sub_url,amount)\n",
    "        all_url.update(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get all men products info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run this!!!!!!\n",
    "l = list(all_url.values())\n",
    "n = len(l)\n",
    "i=0\n",
    "all_man = list()\n",
    "for item in l:\n",
    "    print(i,'/',n)\n",
    "    one_product=one_product_final(item)\n",
    "    all_man.append(one_product)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>write into df and csv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_man_df = pd.DataFrame(all_man, columns = ['product_id', 'brand_name', 'product_name', 'category', 'subcategory', 'loves', 'price', 'total_review', 'avg_rating', 'recommended_count', 'onestar_count', 'twostar_count', 'threestar_count', 'fourstar_count', 'fivestar_count', 'all_reviews'])\n",
    "all_man_df.to_csv('all_man.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
